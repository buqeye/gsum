
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
  
  <!-- Licensed under the Apache 2.0 License -->
  <link rel="stylesheet" type="text/css" href="../../_static/fonts/open-sans/stylesheet.css" />
  <!-- Licensed under the SIL Open Font License -->
  <link rel="stylesheet" type="text/css" href="../../_static/fonts/source-serif-pro/source-serif-pro.css" />
  <link rel="stylesheet" type="text/css" href="../../_static/css/bootstrap.min.css" />
  <link rel="stylesheet" type="text/css" href="../../_static/css/bootstrap-theme.min.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <title>gsum.models &#8212; gsum 0.1 documentation</title>
    <link rel="stylesheet" href="../../_static/guzzle.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  
   

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">gsum 0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="container-wrapper">

      <div id="mobile-toggle">
        <a href="#"><span class="glyphicon glyphicon-align-justify" aria-hidden="true"></span></a>
      </div>
  <div id="left-column">
    <div class="sphinxsidebar"><a href="
    ../../index.html" class="text-logo">gsum</a>
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <h2>Table Of Contents</h2>
  </div>
  <div class="sidebar-toc">
    
    
      <ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
</ul>

    
  </div>
</div>
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <div id="main-search">
      <form class="form-inline" action="../../search.html" method="GET" role="form">
        <div class="input-group">
          <input name="q" type="text" class="form-control" placeholder="Search...">
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div>
      
    </div>
  </div>
        <div id="right-column">
          
          <div role="navigation" aria-label="breadcrumbs navigation">
            <ol class="breadcrumb">
              <li><a href="../../index.html">Docs</a></li>
              
                <li><a href="../index.html">Module code</a></li>
              
              <li>gsum.models</li>
            </ol>
          </div>
          
          <div class="document clearer body">
            
  <h1>Source code for gsum.models</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">.helpers</span> <span class="k">import</span> <span class="n">coefficients</span><span class="p">,</span> <span class="n">hpd</span><span class="p">,</span> <span class="n">mahalanobis</span><span class="p">,</span> <span class="n">geometric_sum</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">solve</span><span class="p">,</span> <span class="n">cholesky</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="k">import</span> <span class="n">cho_solve</span><span class="p">,</span> <span class="n">solve_triangular</span><span class="p">,</span> <span class="n">inv</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="k">import</span> <span class="n">loggamma</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">fmin_l_bfgs_b</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="k">import</span> <span class="n">clone</span>
<span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="k">import</span> <span class="n">RBF</span><span class="p">,</span> <span class="n">ConstantKernel</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="k">import</span> <span class="n">check_X_y</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="k">import</span> <span class="n">ConvergenceWarning</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="k">import</span> <span class="n">itemgetter</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;ConjugateGaussianProcess&#39;</span><span class="p">,</span> <span class="s1">&#39;ConjugateStudentProcess&#39;</span><span class="p">,</span>
    <span class="s1">&#39;TruncationGP&#39;</span><span class="p">,</span> <span class="s1">&#39;TruncationTP&#39;</span><span class="p">,</span> <span class="s1">&#39;TruncationPointwise&#39;</span>
<span class="p">]</span>


<span class="k">class</span> <span class="nc">ConjugateProcess</span><span class="p">:</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A conjugate Gaussian Process model.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel : callable</span>
<span class="sd">        The kernel for the correlation matrix. The covariance matrix is the kernel multiplied by the squared scale.</span>
<span class="sd">    center : float</span>
<span class="sd">        The prior central values for the parameters of the mean function.</span>
<span class="sd">    disp : float &gt;= 0</span>
<span class="sd">        The dispersion parameter for the normal prior placed on the mean. This, multiplied by the squared scale</span>
<span class="sd">        parameter from the inverse chi squared prior, determines the variance of the mean.</span>
<span class="sd">        The smaller the dispersion, the better determined is the mean.</span>
<span class="sd">        Set this to zero for a mean that is known to be `mean`.</span>
<span class="sd">    df : float &gt; 0</span>
<span class="sd">        The degrees of freedom parameter for the inverse chi squared prior placed on the marginal variance.</span>
<span class="sd">        This is a measure of how well the marginal standard deviation (or variance) is known, with</span>
<span class="sd">        larger degrees of freedom implying a better known standard deviation. Set this to infinity for a</span>
<span class="sd">        standard deviation that is known to be `scale`, or use the `sd` keyword argument.</span>
<span class="sd">    scale : float &gt; 0</span>
<span class="sd">        The scale parameter of the scaled inverse chi squared prior placed on the marginal variance</span>
<span class="sd">        of the Gaussian process. Approximately the prior standard deviation for the Gaussian process.</span>
<span class="sd">    sd : float &gt; 0, optional</span>
<span class="sd">        A convenience argument that sets the marginal standard deviation for the Gaussian process.</span>
<span class="sd">        This is equivalent to setting df0 to infinity and scale0 to sd</span>
<span class="sd">        (i.e., a delta function prior on the standard deviation).</span>
<span class="sd">    nugget : float, optional (default: 1e-10)</span>
<span class="sd">        Value added to the diagonal of the correlation matrix during fitting.</span>
<span class="sd">        Larger values correspond to increased noise level in the observations.</span>
<span class="sd">        This can also prevent a potential numerical issue during fitting, by</span>
<span class="sd">        ensuring that the calculated values form a positive definite matrix.</span>
<span class="sd">    optimizer : string or callable, optional (default: &quot;fmin_l_bfgs_b&quot;)</span>
<span class="sd">        Can either be one of the internally supported optimizers for optimizing</span>
<span class="sd">        the kernel&#39;s parameters, specified by a string, or an externally</span>
<span class="sd">        defined optimizer passed as a callable. If a callable is passed, it</span>
<span class="sd">        must have the signature::</span>
<span class="sd">            def optimizer(obj_func, initial_theta, bounds):</span>
<span class="sd">                # * &#39;obj_func&#39; is the objective function to be minimized, which</span>
<span class="sd">                #   takes the hyperparameters theta as parameter and an</span>
<span class="sd">                #   optional flag eval_gradient, which determines if the</span>
<span class="sd">                #   gradient is returned additionally to the function value</span>
<span class="sd">                # * &#39;initial_theta&#39;: the initial value for theta, which can be</span>
<span class="sd">                #   used by local optimizers</span>
<span class="sd">                # * &#39;bounds&#39;: the bounds on the values of theta</span>
<span class="sd">                ....</span>
<span class="sd">                # Returned are the best found hyperparameters theta and</span>
<span class="sd">                # the corresponding value of the target function.</span>
<span class="sd">                return theta_opt, func_min</span>
<span class="sd">        Per default, the &#39;fmin_l_bfgs_b&#39; algorithm from scipy.optimize</span>
<span class="sd">        is used. If None is passed, the kernel&#39;s parameters are kept fixed.</span>
<span class="sd">        Available internal optimizers are::</span>
<span class="sd">            &#39;fmin_l_bfgs_b&#39;</span>
<span class="sd">    n_restarts_optimizer : int, optional (default: 0)</span>
<span class="sd">        The number of restarts of the optimizer for finding the kernel&#39;s</span>
<span class="sd">        parameters which maximize the log-marginal likelihood. The first run</span>
<span class="sd">        of the optimizer is performed from the kernel&#39;s initial parameters,</span>
<span class="sd">        the remaining ones (if any) from thetas sampled log-uniform randomly</span>
<span class="sd">        from the space of allowed theta-values. If greater than 0, all bounds</span>
<span class="sd">        must be finite. Note that n_restarts_optimizer == 0 implies that one</span>
<span class="sd">        run is performed.</span>
<span class="sd">    copy_X_train : bool, optional (default: True)</span>
<span class="sd">        If True, a persistent copy of the training data is stored in the</span>
<span class="sd">        object. Otherwise, just a reference to the training data is stored,</span>
<span class="sd">        which might cause predictions to change if the data is modified</span>
<span class="sd">        externally.</span>
<span class="sd">    random_state : int, RandomState instance or None, optional (default: None)</span>
<span class="sd">        The generator used to initialize the centers. If int, random_state is</span>
<span class="sd">        the seed used by the random number generator; If RandomState instance,</span>
<span class="sd">        random_state is the random number generator; If None, the random number</span>
<span class="sd">        generator is the RandomState instance used by `np.random`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nugget</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span>
                 <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;fmin_l_bfgs_b&#39;</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">copy_X_train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>

        <span class="c1"># Setup hyperparameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_center_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">center</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_disp_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">disp</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sd</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_df_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scale_0</span> <span class="o">=</span> <span class="n">sd</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_df_0</span> <span class="o">=</span> <span class="n">df</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_scale_0</span> <span class="o">=</span> <span class="n">scale</span>

        <span class="c1"># Break with scikit learn convention here. Define all attributes in __init__.</span>
        <span class="c1"># Use value of self._fit to determine whether the `fit` has been called.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disp_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_factor_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">=</span> <span class="n">nugget</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">copy_X_train</span> <span class="o">=</span> <span class="n">copy_X_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_restarts_optimizer</span> <span class="o">=</span> <span class="n">n_restarts_optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_default_kernel</span> <span class="o">=</span> <span class="n">ConstantKernel</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">constant_value_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">)</span> <span class="o">*</span> \
            <span class="n">RBF</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="s1">&#39;fixed&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">basis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">basis</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">center0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_center_0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">disp0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_disp_0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">df0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_df_0</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">scale0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_scale_0</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compute_center</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;Computes the regression coefficients&#39; center hyperparameter :math:`\eta` updated based on data</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_curves, n_samples)</span>
<span class="sd">            The data to condition upon</span>
<span class="sd">        chol : array, shape = (n_samples, n_samples)</span>
<span class="sd">            The cholesky decomposition of the correlation matrix</span>
<span class="sd">        basis : array, shape = (n_samples, n_param)</span>
<span class="sd">            The basis matrix that multiplies the regression coefficients beta to create the GP mean.</span>
<span class="sd">        center0 : scalar or array, shape = (n_param)</span>
<span class="sd">            The prior regression coefficients for the mean</span>
<span class="sd">        disp0 : scalar or array, shape = (n_param, n_param)</span>
<span class="sd">            The prior dispersion for the regression coefficients</span>
<span class="sd">        eval_gradient : bool</span>
<span class="sd">        dR</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        center : scalar or array, shape = (n_param)</span>
<span class="sd">            The posterior regression coefficients for the mean</span>
<span class="sd">        grad_center : array, shape = (n_param, n_kernel_params), optional</span>
<span class="sd">            The gradient of the posterior regression coefficients for the mean with respect to kernel hyperparameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Mean is not updated if its prior variance is zero (i.e. delta function prior)</span>
        <span class="c1"># Do by hand to prevent dividing by zero</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">disp0</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is True&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">center0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="o">*</span><span class="n">center0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dR</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">center0</span><span class="p">)</span>

        <span class="n">y_avg</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">avg_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">ny</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">invR_y_avg</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">y_avg</span><span class="p">)</span>
        <span class="n">disp</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
        <span class="n">factor</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">disp0</span><span class="p">,</span> <span class="n">center0</span><span class="p">)</span> <span class="o">+</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">basis</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">invR_y_avg</span>
        <span class="n">center</span> <span class="o">=</span> <span class="n">disp</span> <span class="o">@</span> <span class="n">factor</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is True&#39;</span><span class="p">)</span>
            <span class="n">invR_basis</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis</span><span class="p">)</span>
            <span class="n">invR_diff</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">center</span> <span class="o">-</span> <span class="n">y_avg</span><span class="p">)</span>
            <span class="n">d_center</span> <span class="o">=</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">disp</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ji,jkp,k-&gt;ip&#39;</span><span class="p">,</span> <span class="n">invR_basis</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">invR_diff</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">center</span><span class="p">,</span> <span class="n">d_center</span>
        <span class="k">return</span> <span class="n">center</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compute_disp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;The dispersion hyperparameter :math:`V` updated based on data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_curves, n_samples)</span>
<span class="sd">            The data to condition upon</span>
<span class="sd">        chol : (n_samples, n_samples)-shaped array</span>
<span class="sd">            The lower Cholesky decomposition of the correlation matrix</span>
<span class="sd">        basis : (n_samples, n_param)-shaped array</span>
<span class="sd">            The basis for the `p` regression coefficients `beta`</span>
<span class="sd">        disp0 : (n_param, n_param)-shaped array</span>
<span class="sd">            The prior dispersion</span>
<span class="sd">        eval_gradient : bool</span>
<span class="sd">        dR</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        disp : (p, p)-shaped array</span>
<span class="sd">            The updated dispersion hyperparameter</span>
<span class="sd">        grad_disp : array, shape = (p,p), optional</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># If prior variance is zero, it stays zero</span>
        <span class="c1"># Do by hand to prevent dividing by zero</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">disp0</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is True&#39;</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disp0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="o">*</span><span class="n">disp0</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dR</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">disp0</span><span class="p">)</span>

        <span class="n">ny</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">quad</span> <span class="o">=</span> <span class="n">mahalanobis</span><span class="p">(</span><span class="n">basis</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">chol</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
        <span class="n">disp</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">inv</span><span class="p">(</span><span class="n">disp0</span><span class="p">)</span> <span class="o">+</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">quad</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is True&#39;</span><span class="p">)</span>
            <span class="n">invRBV</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis</span><span class="p">)</span> <span class="o">@</span> <span class="n">disp</span>
            <span class="n">dV</span> <span class="o">=</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ji,jkp,kl-&gt;ilp&#39;</span><span class="p">,</span> <span class="n">invRBV</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">invRBV</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">disp</span><span class="p">,</span> <span class="n">dV</span>
        <span class="k">return</span> <span class="n">disp</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compute_df</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;Computes the degrees of freedom hyperparameter :math:`\nu` based on data</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_curves, n_samples)</span>
<span class="sd">            The data to condition upon</span>
<span class="sd">        df0 : scalar</span>
<span class="sd">            The prior degrees of freedom</span>
<span class="sd">        eval_gradient</span>
<span class="sd">        dR</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        df : scalar</span>
<span class="sd">            The updated degrees of freedom</span>
<span class="sd">        grad_df : array, size = (n_kernel_params,), optional</span>
<span class="sd">            The gradient of the updated degrees of freedom with respect to the kernel parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">df0</span> <span class="o">+</span> <span class="n">y</span><span class="o">.</span><span class="n">size</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is True&#39;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dR</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compute_scale_sq_v2</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;The squared scale hyperparameter :math:`\tau^2` updated based on data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_samples, [n_curves])</span>
<span class="sd">            The data to condition upon</span>
<span class="sd">        chol : array, shape = (n_samples, n_samples)</span>
<span class="sd">            The lower Cholesky decomposition of the correlation matrix</span>
<span class="sd">        basis : array, shape = (n_samples, n_param)</span>
<span class="sd">            The basis for the `p` regression coefficients `beta`</span>
<span class="sd">        center0 : scalar or array, shape = (n_param)</span>
<span class="sd">            The prior regression coefficients for the mean</span>
<span class="sd">        disp0 : array, shape = (n_param, n_param)</span>
<span class="sd">            The prior dispersion</span>
<span class="sd">        df0 : scalar</span>
<span class="sd">            The prior degrees of freedom hyperparameter</span>
<span class="sd">        scale0 : scalar</span>
<span class="sd">            The prior scale hyperparameter</span>
<span class="sd">        eval_gradient : bool, optional</span>
<span class="sd">            Whether to return to the gradient with respect to kernel hyperparameters. Optional, defaults to False.</span>
<span class="sd">        dR : array, shape = (n_samples, n_samples, n_kernel_params), optional</span>
<span class="sd">            The gradient of the correlation matrix</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scale_sq : scalar</span>
<span class="sd">            The updated scale hyperparameter squared</span>
<span class="sd">        grad_scale_sq : array, shape = (n_kernel_params,), optional</span>
<span class="sd">            The gradient of scale^2 with respect to the kernel hyperparameters. Only returned if eval_gradient is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">df0</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">scale0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dR</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">scale0</span>

        <span class="n">avg_y</span><span class="p">,</span> <span class="n">ny</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">avg_y</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># Compute contributions from a non-zero mean</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">disp0</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="c1"># The disp -&gt; 0 limit must be taken carefully to find these terms</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">center0</span>
            <span class="n">invR_diff0</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">avg_y</span> <span class="o">-</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">center</span><span class="p">)</span>
            <span class="n">mean_terms</span> <span class="o">=</span> <span class="o">-</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">center0</span> <span class="o">@</span> <span class="n">basis</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">invR_diff0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
            <span class="n">mean_terms</span> <span class="o">=</span> <span class="n">center0</span> <span class="o">@</span> <span class="n">inv</span><span class="p">(</span><span class="n">disp0</span><span class="p">)</span> <span class="o">@</span> <span class="n">center0</span> <span class="o">-</span> <span class="n">center</span> <span class="o">@</span> <span class="n">inv</span><span class="p">(</span><span class="n">disp</span><span class="p">)</span> <span class="o">@</span> <span class="n">center</span>

        <span class="c1"># Combine the prior info, quadratic form, and mean contributions to find scale**2</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">invR_y</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">quad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">invR_y</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">scale_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">df0</span> <span class="o">*</span> <span class="n">scale0</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">mean_terms</span> <span class="o">+</span> <span class="n">quad</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is true&#39;</span><span class="p">)</span>
            <span class="c1"># Both the disp -&gt; 0 and non-zero forms have the same gradient formula</span>
            <span class="n">d_scale_sq</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,jkp,ki-&gt;p&#39;</span><span class="p">,</span> <span class="n">invR_y</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">invR_y</span><span class="p">)</span>  <span class="c1"># From the quadratic form</span>
            <span class="n">invR_diff</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">avg_y</span> <span class="o">-</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">center</span><span class="p">)</span>
            <span class="n">invR_basis_center</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis</span><span class="p">)</span> <span class="o">@</span> <span class="n">center</span>
            <span class="n">d_scale_sq</span> <span class="o">+=</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;i,ijp,j-&gt;p&#39;</span><span class="p">,</span> <span class="n">invR_basis_center</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">invR_diff</span><span class="p">)</span>
            <span class="n">d_scale_sq</span> <span class="o">/=</span> <span class="n">df</span>
            <span class="k">return</span> <span class="n">scale_sq</span><span class="p">,</span> <span class="n">d_scale_sq</span>
        <span class="k">return</span> <span class="n">scale_sq</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compute_scale_sq</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;The squared scale hyperparameter :math:`\tau^2` updated based on data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_samples, [n_curves])</span>
<span class="sd">            The data to condition upon</span>
<span class="sd">        chol : array, shape = (n_samples, n_samples)</span>
<span class="sd">            The lower Cholesky decomposition of the correlation matrix</span>
<span class="sd">        basis : array, shape = (n_samples, n_param)</span>
<span class="sd">            The basis for the `p` regression coefficients `beta`</span>
<span class="sd">        center0 : scalar or array, shape = (n_param)</span>
<span class="sd">            The prior regression coefficients for the mean</span>
<span class="sd">        disp0 : array, shape = (n_param, n_param)</span>
<span class="sd">            The prior dispersion</span>
<span class="sd">        df0 : scalar</span>
<span class="sd">            The prior degrees of freedom hyperparameter</span>
<span class="sd">        scale0 : scalar</span>
<span class="sd">            The prior scale hyperparameter</span>
<span class="sd">        eval_gradient : bool</span>
<span class="sd">            Whether to return to the gradient with respect to kernel hyperparameters. Optional, defaults to False.</span>
<span class="sd">        dR : array, shape = (n_samples, n_samples, n_kernel_params)</span>
<span class="sd">            The gradient of the correlation matrix</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        scale_sq : scalar</span>
<span class="sd">            The updated scale hyperparameter squared</span>
<span class="sd">        grad_scale_sq : array, shape = (n_kernel_params,), optional</span>
<span class="sd">            The gradient of scale^2 with respect to the kernel hyperparameters. Only returned if eval_gradient is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">df0</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">scale0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">dR</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">scale0</span>

        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">avg_y</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">avg_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">ny</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">y_centered</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">avg_y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">invR_yc</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">y_centered</span><span class="p">)</span>
        <span class="n">quad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">y_centered</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">invR_yc</span><span class="p">)</span>

        <span class="n">avg_y_centered</span> <span class="o">=</span> <span class="n">avg_y</span> <span class="o">-</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">center0</span>
        <span class="n">disp</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">chol</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">chol</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis</span><span class="p">)</span> <span class="o">@</span> <span class="n">disp</span> <span class="o">@</span> <span class="n">basis</span><span class="o">.</span><span class="n">T</span>
        <span class="n">mat_invR_avg_yc</span> <span class="o">=</span> <span class="n">ny</span> <span class="o">*</span> <span class="n">mat</span> <span class="o">@</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">avg_y_centered</span><span class="p">)</span>
        <span class="n">quad2</span> <span class="o">=</span> <span class="n">avg_y_centered</span> <span class="o">@</span> <span class="n">mat_invR_avg_yc</span>

        <span class="n">df</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">scale_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">df0</span> <span class="o">*</span> <span class="n">scale0</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">quad</span> <span class="o">+</span> <span class="n">quad2</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dR</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;dR must be given if eval_gradient is true&#39;</span><span class="p">)</span>
            <span class="n">d_scale_sq</span> <span class="o">=</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ji,jkp,ki-&gt;p&#39;</span><span class="p">,</span> <span class="n">invR_yc</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">invR_yc</span><span class="p">)</span>
            <span class="n">d_scale_sq</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;i,ijp,j-&gt;p&#39;</span><span class="p">,</span> <span class="n">mat_invR_avg_yc</span><span class="p">,</span> <span class="n">dR</span><span class="p">,</span> <span class="n">mat_invR_avg_yc</span><span class="p">)</span> <span class="o">/</span> <span class="n">ny</span>
            <span class="n">d_scale_sq</span> <span class="o">/=</span> <span class="n">df</span>
            <span class="k">return</span> <span class="n">scale_sq</span><span class="p">,</span> <span class="n">d_scale_sq</span>
        <span class="k">return</span> <span class="n">scale_sq</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;Converts the squared scale hyperparameter :math:`\tau^2` to the correlation -&gt; covariance conversion factor</span>

<span class="sd">        The conversion is given by :math:`\sigma^2 = \nu \tau^2 / (\nu - 2)` for :math:`\nu &gt; 2`</span>

<span class="sd">        Warnings</span>
<span class="sd">        --------</span>
<span class="sd">        If the correlation matrix does equal 1 on the diagonal, :math:`\sigma^2` **will not**</span>
<span class="sd">        be the marginal variance. Instead, one must look at the diagonal of the covariance directly.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">var</span> <span class="o">=</span> <span class="n">scale_sq</span>
        <span class="k">if</span> <span class="n">df</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
            <span class="n">var</span> <span class="o">=</span> <span class="n">df</span> <span class="o">*</span> <span class="n">scale_sq</span> <span class="o">/</span> <span class="p">(</span><span class="n">df</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">var</span>

    <span class="k">def</span> <span class="nf">center</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The regression coefficient hyperparameters for the mean updated by the call to `fit`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">disp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The dispersion hyperparameter updated by the call to `fit`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The degrees of freedom hyperparameter for the standard deviation updated by the call to `fit`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The scale hyperparameter for the standard deviation updated by the call to `fit`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scale_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span>
                                         <span class="n">center0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scale_sq</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;The MAP value for the mean of the process at inputs X with hyperparameters updated by y.</span>

<span class="sd">        This does not interpolate the y values. For that functionality, use `predict`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>  <span class="c1"># Unfitted; predict based on GP prior</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center_</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">center</span>

    <span class="k">def</span> <span class="nf">cov</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">Xp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xp</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>  <span class="c1"># Unfitted; predict based on GP prior</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;df must be greater than 2 for the covariance to exist&#39;</span><span class="p">)</span>
            <span class="n">cov_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale0</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_kernel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cov_factor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_factor_</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span>

        <span class="k">return</span> <span class="n">cov_factor</span> <span class="o">*</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="p">)</span>
    
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the number of curves in y&quot;&quot;&quot;</span>
        <span class="n">ny</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">ny</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ny</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">avg_y</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the average of y over the set of curves</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y : array, shape = (n_samples, [n_curves])</span>
<span class="sd">            The data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        avg_y : array, shape = (n_samples,)</span>
<span class="sd">            The average of y over the set of curves</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calibrate_kernel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">n_dims</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># Choose hyperparameters based on maximizing the log-marginal</span>
            <span class="c1"># likelihood (potentially starting from several initial values)</span>
            <span class="k">def</span> <span class="nf">obj_func</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                    <span class="n">lml</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">(</span>
                        <span class="n">theta</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="k">return</span> <span class="o">-</span><span class="n">lml</span><span class="p">,</span> <span class="o">-</span><span class="n">grad</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

            <span class="c1"># First optimize starting from theta specified in kernel</span>
            <span class="n">optima</span> <span class="o">=</span> <span class="p">[(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constrained_optimization</span><span class="p">(</span><span class="n">obj_func</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                                                      <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">bounds</span><span class="p">))]</span>

            <span class="c1"># Additional runs are performed from log-uniform chosen initial</span>
            <span class="c1"># theta</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_restarts_optimizer</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">bounds</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;Multiple optimizer restarts (n_restarts_optimizer&gt;0) &quot;</span>
                        <span class="s2">&quot;requires that all bounds are finite.&quot;</span><span class="p">)</span>
                <span class="n">bounds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">bounds</span>
                <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_restarts_optimizer</span><span class="p">):</span>
                    <span class="n">theta_initial</span> <span class="o">=</span> \
                        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">bounds</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">bounds</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="n">optima</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_optimization</span><span class="p">(</span><span class="n">obj_func</span><span class="p">,</span> <span class="n">theta_initial</span><span class="p">,</span>
                                                       <span class="n">bounds</span><span class="p">))</span>
            <span class="c1"># Select result from run with minimal (negative) log-marginal</span>
            <span class="c1"># likelihood</span>
            <span class="n">lml_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">itemgetter</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">optima</span><span class="p">))</span>
            <span class="n">optima</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">optima</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">optima</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">lml_values</span><span class="p">)][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood_value_</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">lml_values</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood_value_</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">theta</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;Fits the process to data (X, y) and updates all hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape = (n_samples, n_features)</span>
<span class="sd">            The input variables where the response is observed</span>
<span class="sd">        y : array, shape = (n_samples, [n_curves])</span>
<span class="sd">            The response values</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : returns an instance of self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># Use an RBF kernel as default</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_kernel</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">check_X_y</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">multi_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">y_numeric</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_X_train</span> <span class="k">else</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_X_train</span> <span class="k">else</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_calibrate_kernel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">center_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">disp_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">scale_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span><span class="p">,</span>
                                         <span class="n">center0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scale_sq</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_factor_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="n">scale_sq</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">underlying_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">y_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_cov</span>
        <span class="k">elif</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
            <span class="k">return</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_mean</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Xc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the predictive GP at the points X</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array, shape = (n_samples, n_features)</span>
<span class="sd">            Locations at which to predict the new y values</span>
<span class="sd">        return_std : bool</span>
<span class="sd">            Whether the marginal standard deviation of the predictive process is to be returned</span>
<span class="sd">        return_cov : bool</span>
<span class="sd">            Whether the covariance matrix of the predictive process is to be returned</span>
<span class="sd">        Xc : array, shape = (n_conditional_samples, n_features)</span>
<span class="sd">            Locations at which to condition. Defaults to `X` used in fit. This *does not*</span>
<span class="sd">            affect the `X` used to update hyperparameters.</span>
<span class="sd">        y : array, shape = (n_conditional_samples, [n_curves])</span>
<span class="sd">            Points upon which to condition. Defaults to the `y` used in `fit`. This *does not*</span>
<span class="sd">            affect the `y` used to update hyperparameters.</span>
<span class="sd">        pred_noise : bool, optional</span>
<span class="sd">            Adds `noise_sd` to the diagonal of the covariance matrix if `return_cov == True`.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y_mean : array, shape = (n_curves, n_samples)</span>
<span class="sd">            Mean of predictive distribution at query points</span>
<span class="sd">        y_std : array, shape = (n_samples,), optional</span>
<span class="sd">            Standard deviation of predictive distribution at query points.</span>
<span class="sd">            Only returned when return_std is True.</span>
<span class="sd">        y_cov : array, shape = (n_samples, n_samples), optional</span>
<span class="sd">            Covariance of joint predictive distribution at query points.</span>
<span class="sd">            Only returned when return_cov is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">return_std</span> <span class="ow">and</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Only one of return_std or return_cov may be True&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>  <span class="c1"># Unfitted; predict based on GP prior</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_properties</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="n">return_std</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="n">return_cov</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Xc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>
            <span class="n">corr_chol</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">corr_chol</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span>

        <span class="c1"># Use X and y from fit for hyperparameters</span>
        <span class="n">m_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span>
        <span class="n">m_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Now use X and y from arguments for conditioning/predictions</span>
        <span class="n">R_on</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">Xc</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">R_no</span> <span class="o">=</span> <span class="n">R_on</span><span class="o">.</span><span class="n">T</span>
        <span class="n">R_nn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="c1"># Use given y for prediction</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">corr_chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">m_old</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]))</span>
        <span class="n">m_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">m_new</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">R_no</span> <span class="o">@</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">half_quad</span> <span class="o">=</span> <span class="n">solve_triangular</span><span class="p">(</span><span class="n">corr_chol</span><span class="p">,</span> <span class="n">R_on</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">R_pred</span> <span class="o">=</span> <span class="n">R_nn</span> <span class="o">-</span> <span class="n">half_quad</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">half_quad</span>
            <span class="k">if</span> <span class="n">pred_noise</span><span class="p">:</span>
                <span class="n">R_pred</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
            <span class="c1"># Use y from fit for hyperparameters</span>
            <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_</span><span class="p">)</span>
            <span class="n">K_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">var</span> <span class="o">*</span> <span class="n">R_pred</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">m_pred</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">K_pred</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">m_pred</span><span class="p">,</span> <span class="n">K_pred</span>
        <span class="k">return</span> <span class="n">m_pred</span>

    <span class="k">def</span> <span class="nf">sample_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">underlying</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Taken from scikit-learn&#39;s gp module&quot;&quot;&quot;</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">underlying</span><span class="p">:</span>
            <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_properties</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y_mean</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_samples</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">y_mean</span><span class="p">,</span> <span class="n">y_cov</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_samples</span> <span class="o">=</span> \
                <span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">y_mean</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_cov</span><span class="p">,</span>
                                         <span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
                 <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_mean</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
            <span class="n">y_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">y_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_samples</span>

    <span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="c1"># def likelihood(self, log=True, X=None, y=None, **kernel_kws):</span>
    <span class="c1">#     raise NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_constrained_optimization</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj_func</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">bounds</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">==</span> <span class="s2">&quot;fmin_l_bfgs_b&quot;</span><span class="p">:</span>
            <span class="n">theta_opt</span><span class="p">,</span> <span class="n">func_min</span><span class="p">,</span> <span class="n">convergence_dict</span> <span class="o">=</span> \
                <span class="n">fmin_l_bfgs_b</span><span class="p">(</span><span class="n">obj_func</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">convergence_dict</span><span class="p">[</span><span class="s2">&quot;warnflag&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;fmin_l_bfgs_b terminated abnormally with the &quot;</span>
                              <span class="s2">&quot; state: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">convergence_dict</span><span class="p">,</span>
                              <span class="n">ConvergenceWarning</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">):</span>
            <span class="n">theta_opt</span><span class="p">,</span> <span class="n">func_min</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">(</span><span class="n">obj_func</span><span class="p">,</span> <span class="n">initial_theta</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unknown optimizer </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">theta_opt</span><span class="p">,</span> <span class="n">func_min</span>

        
<div class="viewcode-block" id="ConjugateGaussianProcess"><a class="viewcode-back" href="../../api/models.html#gsum.models.ConjugateGaussianProcess">[docs]</a><span class="k">class</span> <span class="nc">ConjugateGaussianProcess</span><span class="p">(</span><span class="n">ConjugateProcess</span><span class="p">):</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A conjugacy-based Gaussian Process class.</span>

<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="ConjugateGaussianProcess.log_marginal_likelihood"><a class="viewcode-back" href="../../api/models.html#gsum.models.ConjugateGaussianProcess.log_marginal_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns log-marginal likelihood of theta for training data.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : array-like, shape = (n_kernel_params,) or None</span>
<span class="sd">            Kernel hyperparameters for which the log-marginal likelihood is</span>
<span class="sd">            evaluated. If None, the precomputed log_marginal_likelihood</span>
<span class="sd">            of ``self.kernel_.theta`` is returned.</span>
<span class="sd">        eval_gradient : bool, default: False</span>
<span class="sd">            If True, the gradient of the log-marginal likelihood with respect</span>
<span class="sd">            to the kernel hyperparameters at position theta is returned</span>
<span class="sd">            additionally. If True, theta must not be None.</span>
<span class="sd">        y : array, shape = (n_samples, [n_curves]), optional</span>
<span class="sd">            The observed data to use. Defaults to `y` passed in `fit`.</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        log_likelihood : float</span>
<span class="sd">            Log-marginal likelihood of theta for training data.</span>
<span class="sd">        log_likelihood_gradient : array, shape = (n_kernel_params,), optional</span>
<span class="sd">            Gradient of the log-marginal likelihood with respect to the kernel</span>
<span class="sd">            hyperparameters at position theta.</span>
<span class="sd">            Only returned when eval_gradient is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">theta</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;Gradient can only be evaluated for theta!=None&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_marginal_likelihood_value_</span>

        <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">clone_with_theta</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">R</span><span class="p">,</span> <span class="n">R_gradient</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">R</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">)</span>
            <span class="n">R_gradient</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">R</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices_from</span><span class="p">(</span><span class="n">R</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">corr_L</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>  <span class="c1"># Line 2</span>
        <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span> \
                <span class="k">if</span> <span class="n">eval_gradient</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">y</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>
        <span class="c1"># Support multi-dimensional output of self.y_train_</span>
        <span class="k">if</span> <span class="n">y_train</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

        <span class="c1"># ---------------------------------</span>
        <span class="c1"># Conjugacy-specific code.</span>
        <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">center</span><span class="p">,</span> <span class="n">grad_center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
                                                      <span class="n">eval_gradient</span><span class="o">=</span><span class="n">eval_gradient</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="n">R_gradient</span><span class="p">)</span>
            <span class="n">scale2</span><span class="p">,</span> <span class="n">dscale2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
                <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="n">eval_gradient</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="n">R_gradient</span><span class="p">)</span>
            <span class="n">grad_var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="n">dscale2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
            <span class="n">grad_mean</span> <span class="o">=</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">grad_center</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
            <span class="n">scale2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
                <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">)</span>
            <span class="n">grad_center</span><span class="p">,</span> <span class="n">grad_var</span><span class="p">,</span> <span class="n">grad_mean</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">basis</span> <span class="o">@</span> <span class="n">center</span>
        <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="n">scale2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

        <span class="c1"># Convert from correlation matrix to covariance and subtract mean</span>
        <span class="c1"># to make all calculations below identical to scikit learn implementation</span>
        <span class="n">L</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">)</span> <span class="o">*</span> <span class="n">corr_L</span>
        <span class="n">K</span><span class="p">,</span> <span class="n">K_gradient</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="n">R</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">K_gradient</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="n">R_gradient</span> <span class="o">+</span> <span class="n">grad_var</span> <span class="o">*</span> <span class="n">R</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">-</span> <span class="n">mean</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="c1"># ---------------------------------</span>
        <span class="c1"># Resume likelihood calculation</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># Line 3</span>

        <span class="c1"># Compute log-likelihood (compare line 7)</span>
        <span class="n">log_likelihood_dims</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,ik-&gt;k&quot;</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
        <span class="n">log_likelihood_dims</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">L</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="n">log_likelihood_dims</span> <span class="o">-=</span> <span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">log_likelihood_dims</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># sum over dimensions</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>  <span class="c1"># compare Equation 5.9 from GP for ML</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ik,jk-&gt;ijk&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>  <span class="c1"># k: output-dimension</span>
            <span class="n">tmp</span> <span class="o">-=</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))[:,</span> <span class="p">:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
            <span class="c1"># Compute &quot;0.5 * trace(tmp.dot(K_gradient))&quot; without</span>
            <span class="c1"># constructing the full matrix tmp.dot(K_gradient) since only</span>
            <span class="c1"># its diagonal is required</span>
            <span class="n">log_likelihood_gradient_dims</span> <span class="o">=</span> \
                <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ijl,ijk-&gt;kl&quot;</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="n">K_gradient</span><span class="p">)</span>

            <span class="c1"># Beyond scikit-learn: Add gradient wrt mean</span>
            <span class="n">log_likelihood_gradient_dims</span> <span class="o">-=</span> <span class="n">grad_mean</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">alpha</span>

            <span class="c1"># Sum over output dimension</span>
            <span class="n">log_likelihood_gradient</span> <span class="o">=</span> <span class="n">log_likelihood_gradient_dims</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">log_likelihood</span><span class="p">,</span> <span class="n">log_likelihood_gradient</span>
        <span class="k">return</span> <span class="n">log_likelihood</span></div>

    <span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Multiple corr can be passed to quickly get likelihoods for many correlation parameters</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span>

        <span class="c1"># corr = self.kernel(X, **self.kernel_kws)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">clone_with_theta</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="n">corr</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">corr</span> <span class="o">=</span> <span class="n">corr</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">corr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">corr_chol</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>
        
        <span class="c1"># Setup best guesses for mean and cov</span>
        <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">basis</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_center</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">corr_chol</span><span class="p">,</span> <span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
        <span class="c1"># sd = self.compute_std(y=y, chol=corr_chol, basis=basis, beta0=beta0, disp0=disp0, df0=df0, scale0=scale0)</span>
        <span class="n">scale2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span>
            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_chol</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
            <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">)</span>
        <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="n">scale2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
        <span class="n">cov</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="n">corr</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>
        <span class="n">log_like</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">log</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">log_like</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_like</span><span class="p">)</span></div>


<div class="viewcode-block" id="ConjugateStudentProcess"><a class="viewcode-back" href="../../api/models.html#gsum.models.ConjugateStudentProcess">[docs]</a><span class="k">class</span> <span class="nc">ConjugateStudentProcess</span><span class="p">(</span><span class="n">ConjugateProcess</span><span class="p">):</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A conjugacy-based Student-t Process class.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">cov</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">Xp</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xp</span> <span class="o">=</span> <span class="n">X</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>  <span class="c1"># Unfitted; predict based on GP prior</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp0</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_kernel</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df_</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp_</span>
            <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span>

        <span class="k">if</span> <span class="n">df</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;df must be greater than 2 for the covariance to exist&#39;</span><span class="p">)</span>

        <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
        <span class="n">corr</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">var</span> <span class="o">*</span> <span class="p">(</span><span class="n">corr</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">disp</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">Xp</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

<div class="viewcode-block" id="ConjugateStudentProcess.predict"><a class="viewcode-back" href="../../api/models.html#gsum.models.ConjugateStudentProcess.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Xc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">ConjugateStudentProcess</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="n">return_std</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="n">return_cov</span><span class="p">,</span> <span class="n">Xc</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="n">pred_noise</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>  <span class="c1"># Unfitted; predict based on GP prior</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp0</span>
            <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_cov_factor</span><span class="p">(</span><span class="n">scale_sq</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale0</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">)</span>
            <span class="n">basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp_</span>
            <span class="n">var</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov_factor_</span>
            <span class="n">basis_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">Xc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">basis_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis_train_</span>
                <span class="n">corr_chol</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">corr_L_</span>
                <span class="n">R_no</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">basis_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span>
                <span class="n">R_no</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Xc</span><span class="p">)</span>
                <span class="n">corr_chol</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="p">(</span><span class="n">Xc</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xc</span><span class="p">)))</span>
            <span class="c1"># The conditional basis</span>
            <span class="n">basis</span> <span class="o">=</span> <span class="n">basis_new</span> <span class="o">-</span> <span class="n">R_no</span> <span class="o">@</span> <span class="n">cho_solve</span><span class="p">((</span><span class="n">corr_chol</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">basis_old</span><span class="p">)</span>

        <span class="n">mean_cov</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="p">(</span><span class="n">basis</span> <span class="o">@</span> <span class="n">disp</span> <span class="o">@</span> <span class="n">basis</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>  <span class="c1"># From integrating out the mean</span>
        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">pred</span>
            <span class="n">std</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">mean_cov</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">pred</span>
            <span class="n">cov</span> <span class="o">+=</span> <span class="n">mean_cov</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span>
        <span class="k">return</span> <span class="n">pred</span></div>

    <span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>

        <span class="n">ny</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_y</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kernel_</span><span class="o">.</span><span class="n">clone_with_theta</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">R</span><span class="p">,</span> <span class="n">dR</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">R</span><span class="p">,</span> <span class="n">dR</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="kc">None</span>

        <span class="n">R</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">diag_indices_from</span><span class="p">(</span><span class="n">R</span><span class="p">)]</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nugget</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">corr_L</span> <span class="o">=</span> <span class="n">cholesky</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>  <span class="c1"># Line 2</span>
        <span class="k">except</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinAlgError</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">theta</span><span class="p">))</span> \
                <span class="k">if</span> <span class="n">eval_gradient</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">disp0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_df</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">disp</span><span class="p">,</span> <span class="n">grad_disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
                                                <span class="n">eval_gradient</span><span class="o">=</span><span class="n">eval_gradient</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="n">dR</span><span class="p">)</span>
            <span class="n">scale_sq</span><span class="p">,</span> <span class="n">grad_scale_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span>
                <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="n">eval_gradient</span><span class="p">,</span> <span class="n">dR</span><span class="o">=</span><span class="n">dR</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_disp</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">)</span>
            <span class="n">scale_sq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_scale_sq</span><span class="p">(</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">chol</span><span class="o">=</span><span class="n">corr_L</span><span class="p">,</span> <span class="n">basis</span><span class="o">=</span><span class="n">basis</span><span class="p">,</span> <span class="n">center0</span><span class="o">=</span><span class="n">center0</span><span class="p">,</span> <span class="n">disp0</span><span class="o">=</span><span class="n">disp0</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">)</span>
            <span class="n">grad_disp</span><span class="p">,</span> <span class="n">grad_scale_sq</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">scale_sq</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">log_norm</span><span class="p">(</span><span class="n">df_</span><span class="p">,</span> <span class="n">scale_</span><span class="p">,</span> <span class="n">disp_</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Normalization constant of the normal scaled inverse chi squared distribution&quot;&quot;&quot;</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">df_</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span> <span class="o">-</span> <span class="n">df_</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df_</span> <span class="o">*</span> <span class="n">scale_</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span>
            <span class="n">log_det</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">disp_</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">log_det</span> <span class="o">!=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">:</span>
                <span class="n">norm</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">log_det</span>
            <span class="k">return</span> <span class="n">norm</span>

        <span class="n">log_det_corr</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">corr_L</span><span class="p">)))</span>
        <span class="n">log_like</span> <span class="o">=</span> <span class="n">log_norm</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">disp</span><span class="p">)</span> <span class="o">-</span> <span class="n">log_norm</span><span class="p">(</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="p">,</span> <span class="n">disp0</span><span class="p">)</span> <span class="o">-</span> <span class="n">ny</span> <span class="o">/</span> <span class="mf">2.</span> <span class="o">*</span> <span class="n">log_det_corr</span>

        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="c1"># cho_solve only cares about first dimension of dR. Gradient parameters are in the last dimension.</span>
            <span class="n">log_like_gradient</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">ny</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">cho_solve</span><span class="p">((</span><span class="n">corr_L</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">dR</span><span class="p">),</span> <span class="n">axis1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis2</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">log_like_gradient</span> <span class="o">-=</span> <span class="p">(</span><span class="n">df</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span> <span class="o">*</span> <span class="n">grad_scale_sq</span> <span class="o">/</span> <span class="n">scale_sq</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">disp</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">log_like_gradient</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ij,ijp-&gt;p&#39;</span><span class="p">,</span> <span class="n">inv</span><span class="p">(</span><span class="n">disp</span><span class="p">),</span> <span class="n">grad_disp</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">log_like</span><span class="p">,</span> <span class="n">log_like_gradient</span>

        <span class="k">return</span> <span class="n">log_like</span></div>

    <span class="c1"># def likelihood(self, log=True, X=None, y=None, **kernel_kws):</span>
    <span class="c1">#     if X is None:</span>
    <span class="c1">#         X = self.X_train_</span>
    <span class="c1">#     if y is None:</span>
    <span class="c1">#         y = self.y_train_</span>
    <span class="c1">#</span>
    <span class="c1">#     ny = self.num_y(y)</span>
    <span class="c1">#     corr = self.kernel(X, X, **kernel_kws)</span>
    <span class="c1">#     corr_chol = cholesky(corr + self.nugget * np.eye(corr.shape[-1]))</span>
    <span class="c1">#</span>
    <span class="c1">#     beta0, disp0, df0, scale0 = self.beta0, self.disp0, self.df0, self.scale0</span>
    <span class="c1">#     df = self.compute_df(y=y, df0=df0)</span>
    <span class="c1">#     basis = self.basis(X)</span>
    <span class="c1">#     disp = self.compute_disp(y=y, chol=corr_chol, basis=basis, disp0=disp0)</span>
    <span class="c1">#     scale = self.compute_scale(y=y, chol=corr_chol, basis=basis, beta0=beta0, disp0=disp0, df0=df0, scale0=scale0)</span>
    <span class="c1">#</span>
    <span class="c1">#     def log_norm(df_, scale_, disp_):</span>
    <span class="c1">#         &quot;&quot;&quot;Normalization constant of the normal scaled inverse chi squared distribution&quot;&quot;&quot;</span>
    <span class="c1">#         norm = loggamma(df_ / 2.) - df_ / 2. * np.log(df_ * scale_ / 2.)</span>
    <span class="c1">#         log_det = np.linalg.slogdet(2 * np.pi * disp_)[1]</span>
    <span class="c1">#         if log_det != -np.inf:</span>
    <span class="c1">#             norm += 0.5 * log_det</span>
    <span class="c1">#         return norm</span>
    <span class="c1">#</span>
    <span class="c1">#     log_det_corr = 2 * np.sum(np.log(2 * np.pi * np.diagonal(corr_chol)))</span>
    <span class="c1">#     log_like = log_norm(df, scale, disp) - log_norm(df0, scale0, disp0) - ny / 2. * log_det_corr</span>
    <span class="c1">#</span>
    <span class="c1">#     # log_like = np.array([log_norm(df, scale, disp) for scale, disp in zip(scale_vec, disp_vec)])</span>
    <span class="c1">#     # log_det_corr = 2 * np.sum(np.log(2 * np.pi * np.diagonal(corr_chol_vec, axis1=-2, axis2=-1)), axis=-1)</span>
    <span class="c1">#     # log_like -= ny / 2. * log_det_corr + log_norm(df0, scale0, disp0)</span>
    <span class="c1">#</span>
    <span class="c1">#     if log:</span>
    <span class="c1">#         return log_like</span>
    <span class="c1">#     return np.exp(log_like)</span>


<span class="k">class</span> <span class="nc">TruncationProcess</span><span class="p">:</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    kernel</span>
<span class="sd">    ratio</span>
<span class="sd">    ref</span>
<span class="sd">    excluded : 1d array</span>
<span class="sd">        The set of orders to ignore when constructing process for y_order and dy_order, i.e., the geometric sum</span>
<span class="sd">        will not include these values</span>
<span class="sd">    ratio_kws</span>
<span class="sd">    kernel_kws</span>
<span class="sd">    nugget</span>
<span class="sd">    verbose</span>
<span class="sd">    kwargs</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio_kws</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">ref</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">:</span> <span class="n">ref</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ref</span> <span class="o">=</span> <span class="n">ref</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">ratio</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">X</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">:</span> <span class="n">ratio</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span> <span class="o">=</span> <span class="n">ratio</span>

        <span class="c1"># self.coeffs_process_class = ConjugateProcess</span>
        <span class="c1"># self.coeffs_process = self.coeffs_process_class(kernel=kernel, **kwargs)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span> <span class="o">=</span> <span class="n">ConjugateProcess</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_log_like</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio_kws</span> <span class="o">=</span> <span class="p">{}</span> <span class="k">if</span> <span class="n">ratio_kws</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">ratio_kws</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dX_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dy_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="c1"># self.coeffs_process_ = None</span>

    <span class="k">def</span> <span class="nf">mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="n">coeff_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="n">ratio_sum</span> <span class="o">=</span> <span class="n">geometric_sum</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio_sum</span> <span class="o">*</span> <span class="n">coeff_mean</span>

    <span class="k">def</span> <span class="nf">cov</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="n">Xp</span> <span class="o">=</span> <span class="n">X</span> <span class="k">if</span> <span class="n">Xp</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">Xp</span>
        <span class="n">coeff_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">Xp</span><span class="p">)</span>
        <span class="n">ratio_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">Xp</span><span class="p">)</span>
        <span class="n">ratio_sum</span> <span class="o">=</span> <span class="n">geometric_sum</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">ratio_mat</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
        <span class="n">ref_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">Xp</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ref_mat</span> <span class="o">*</span> <span class="n">ratio_sum</span> <span class="o">*</span> <span class="n">coeff_cov</span>

    <span class="k">def</span> <span class="nf">basis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
        <span class="n">cn_basis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
        <span class="n">ratio_sum</span> <span class="o">=</span> <span class="n">geometric_sum</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">start</span><span class="o">=</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">end</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">X</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">ratio_sum</span> <span class="o">*</span> <span class="n">cn_basis</span>

    <span class="k">def</span> <span class="nf">underlying_properties</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">y_mean</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">y_cov</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_cov</span>
        <span class="k">elif</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="n">y_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
            <span class="k">return</span> <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_std</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y_mean</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">orders</span><span class="p">,</span> <span class="n">dX</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dy</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span> <span class="o">=</span> <span class="n">orders</span>
        <span class="n">orders_mask</span> <span class="o">=</span> <span class="o">~</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dX_</span> <span class="o">=</span> <span class="n">dX</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dy_</span> <span class="o">=</span> <span class="n">dy</span>

        <span class="c1"># Extract the coefficients based on best ratio value and setup/fit the iid coefficient process</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">ratio_kws</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">orders</span><span class="o">=</span><span class="n">orders</span><span class="p">)[:,</span> <span class="n">orders_mask</span><span class="p">]</span>
        <span class="c1"># self.coeffs_process_ = self.coeffs_process_class(kernel=self.kernel, **self.coeffs_process_kwargs)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Xc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the predictive GP at the points X</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : (M, d) array</span>
<span class="sd">            Locations at which to predict the new y values</span>
<span class="sd">        order : int</span>
<span class="sd">            The order of the GP to predict</span>
<span class="sd">        return_std : bool</span>
<span class="sd">            Whether the marginal standard deviation of the predictive process is to be returned</span>
<span class="sd">        return_cov : bool</span>
<span class="sd">            Whether the covariance matrix of the predictive process is to be returned</span>
<span class="sd">        Xc : (N, d) array</span>
<span class="sd">            Locations at which to condition. Defaults to `X` used in fit. This *does not*</span>
<span class="sd">            affect the `X` used to update hyperparameters.</span>
<span class="sd">        y : (n, N) array</span>
<span class="sd">            Points upon which to condition. Defaults to the `y` used in `fit`. This *does not*</span>
<span class="sd">            affect the `y` used to update hyperparameters.</span>
<span class="sd">        pred_noise : bool</span>
<span class="sd">            Adds `noise_sd` to the diagonal of the covariance matrix if `return_cov == True`.</span>
<span class="sd">        kind : str</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mean, (mean, std), or (mean, cov), depending on `return_std` and `return_cov`</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">underlying_properties</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="n">return_cov</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="n">return_std</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">Xc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>
        <span class="k">if</span> <span class="n">y</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">order</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;order must be in orders passed to `fit`&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span> <span class="o">==</span> <span class="n">order</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">kind</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="s1">&#39;interp&#39;</span><span class="p">,</span> <span class="s1">&#39;trunc&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;kind must be one of &quot;both&quot;, &quot;interp&quot; or &quot;trunc&quot;&#39;</span><span class="p">)</span>

        <span class="n">m_pred</span><span class="p">,</span> <span class="n">K_pred</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;both&#39;</span> <span class="ow">or</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;interp&#39;</span><span class="p">:</span>
            <span class="c1"># ----------------------------------------------------</span>
            <span class="c1"># Get mean &amp; cov for (interpolating) prediction y_order</span>
            <span class="c1">#</span>
            <span class="c1"># Use X and y from fit for hyperparameters</span>
            <span class="n">m_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
            <span class="n">m_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>

            <span class="c1"># Use X and y from arguments for conditioning/predictions</span>
            <span class="n">K_oo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">Xc</span><span class="p">)</span>
            <span class="n">K_on</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>
            <span class="n">K_no</span> <span class="o">=</span> <span class="n">K_on</span><span class="o">.</span><span class="n">T</span>
            <span class="n">K_nn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

            <span class="c1"># Use given y for prediction</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo</span><span class="p">,</span> <span class="n">y</span> <span class="o">-</span> <span class="n">m_old</span><span class="p">)</span>
            <span class="n">m_pred</span> <span class="o">+=</span> <span class="n">m_new</span> <span class="o">+</span> <span class="n">K_no</span> <span class="o">@</span> <span class="n">alpha</span>
            <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">:</span>
                <span class="n">K_pred</span> <span class="o">+=</span> <span class="n">K_nn</span> <span class="o">-</span> <span class="n">K_no</span> <span class="o">@</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo</span><span class="p">,</span> <span class="n">K_on</span><span class="p">)</span>
            <span class="c1">#</span>
            <span class="c1"># ----------------------------------------------------</span>

        <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;both&#39;</span> <span class="ow">or</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;trunc&#39;</span><span class="p">:</span>
            <span class="c1"># ----------------------------------------------------</span>
            <span class="c1"># Get the mean &amp; cov for truncation error</span>
            <span class="c1">#</span>
            <span class="n">m_new_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
            <span class="n">K_nn_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

            <span class="n">X_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dX_</span>
            <span class="k">if</span> <span class="n">X_trunc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># truncation error is constrained</span>
                <span class="n">m_old_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">K_oo_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">K_on_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">K_no_trunc</span> <span class="o">=</span> <span class="n">K_on_trunc</span><span class="o">.</span><span class="n">T</span>

                <span class="n">alpha_trunc</span> <span class="o">=</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo_trunc</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dy_</span> <span class="o">-</span> <span class="n">m_old_trunc</span><span class="p">))</span>
                <span class="n">m_pred</span> <span class="o">+=</span> <span class="n">m_new_trunc</span> <span class="o">+</span> <span class="n">K_no_trunc</span> <span class="o">@</span> <span class="n">alpha_trunc</span>
                <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">:</span>
                    <span class="n">K_pred</span> <span class="o">+=</span> <span class="n">K_nn_trunc</span> <span class="o">-</span> <span class="n">K_no_trunc</span> <span class="o">@</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo_trunc</span><span class="p">,</span> <span class="n">K_on_trunc</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># truncation is not constrained</span>
                <span class="n">m_pred</span> <span class="o">+=</span> <span class="n">m_new_trunc</span>
                <span class="k">if</span> <span class="n">return_std</span> <span class="ow">or</span> <span class="n">return_cov</span><span class="p">:</span>
                    <span class="n">K_pred</span> <span class="o">+=</span> <span class="n">K_nn_trunc</span>

        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">m_pred</span><span class="p">,</span> <span class="n">K_pred</span>
        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">m_pred</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">K_pred</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">m_pred</span>

    <span class="k">def</span> <span class="nf">log_marginal_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">ratio_kws</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_train_</span>
        <span class="n">orders</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span>
        <span class="n">ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">ratio_kws</span><span class="p">)</span>

        <span class="n">orders_mask</span> <span class="o">=</span> <span class="o">~</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="n">orders</span><span class="p">)[:,</span> <span class="n">orders_mask</span><span class="p">]</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">log_marginal_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">eval_gradient</span><span class="o">=</span><span class="n">eval_gradient</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">coeffs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">eval_gradient</span><span class="p">:</span>
            <span class="n">coeff_log_like</span><span class="p">,</span> <span class="n">coeff_log_like_gradient</span> <span class="o">=</span> <span class="n">result</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">coeff_log_like</span> <span class="o">=</span> <span class="n">result</span>

        <span class="n">orders_in</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="n">orders_mask</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">orders_in</span><span class="p">)</span>
        <span class="n">det_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ref</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">orders_in</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ratio</span><span class="p">)))</span>
        <span class="n">y_log_like</span> <span class="o">=</span> <span class="n">coeff_log_like</span> <span class="o">-</span> <span class="n">det_factor</span>
        <span class="k">return</span> <span class="n">y_log_like</span>


<div class="viewcode-block" id="TruncationGP"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationGP">[docs]</a><span class="k">class</span> <span class="nc">TruncationGP</span><span class="p">(</span><span class="n">TruncationProcess</span><span class="p">):</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A Gaussian Process Truncation class&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio_kws</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="n">excluded</span><span class="p">,</span> <span class="n">ratio_kws</span><span class="o">=</span><span class="n">ratio_kws</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span> <span class="o">=</span> <span class="n">ConjugateGaussianProcess</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="TruncationTP"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationTP">[docs]</a><span class="k">class</span> <span class="nc">TruncationTP</span><span class="p">(</span><span class="n">TruncationProcess</span><span class="p">):</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A Student-t Process Truncation class&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ratio_kws</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="n">excluded</span><span class="p">,</span> <span class="n">ratio_kws</span><span class="o">=</span><span class="n">ratio_kws</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span> <span class="o">=</span> <span class="n">ConjugateStudentProcess</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<div class="viewcode-block" id="TruncationTP.predict"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationTP.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">Xc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">TruncationTP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
            <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="n">return_std</span><span class="p">,</span> <span class="n">return_cov</span><span class="o">=</span><span class="n">return_cov</span><span class="p">,</span>
            <span class="n">Xc</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">pred_noise</span><span class="o">=</span><span class="n">pred_noise</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_std</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">pred</span>

        <span class="k">if</span> <span class="n">Xc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_train_</span>

        <span class="n">var</span><span class="p">,</span> <span class="n">disp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">cov_factor_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_process</span><span class="o">.</span><span class="n">disp_</span>
        <span class="n">basis_lower</span><span class="p">,</span> <span class="n">basis_trunc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">disp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">disp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;both&#39;</span> <span class="ow">or</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;interp&#39;</span><span class="p">:</span>
            <span class="c1"># Use Xc from argument to define old points</span>
            <span class="n">K_oo</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
            <span class="n">K_no</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>

            <span class="n">basis_lower_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">Xc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
            <span class="n">basis_lower_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
            <span class="n">basis_lower</span> <span class="o">=</span> <span class="n">basis_lower_new</span> <span class="o">-</span> <span class="n">K_no</span> <span class="o">@</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo</span><span class="p">,</span> <span class="n">basis_lower_old</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;both&#39;</span> <span class="ow">or</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;trunc&#39;</span><span class="p">:</span>
            <span class="n">X_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dX_</span>
            <span class="k">if</span> <span class="n">X_trunc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># truncation error is constrained</span>
                <span class="n">K_oo_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">K_no_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">Xp</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>

                <span class="n">basis_trunc_old</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_trunc</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">basis_trunc_new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
                <span class="n">basis_trunc</span> <span class="o">=</span> <span class="n">basis_trunc_new</span> <span class="o">-</span> <span class="n">K_no_trunc</span> <span class="o">@</span> <span class="n">solve</span><span class="p">(</span><span class="n">K_oo_trunc</span><span class="p">,</span> <span class="n">basis_trunc_old</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># not constrained</span>
                <span class="n">basis_trunc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

        <span class="n">mean_cov</span> <span class="o">=</span> <span class="n">var</span> <span class="o">*</span> <span class="p">(</span><span class="n">basis_lower</span> <span class="o">+</span> <span class="n">basis_trunc</span><span class="p">)</span> <span class="o">@</span> <span class="n">disp</span> <span class="o">@</span> <span class="p">(</span><span class="n">basis_lower</span> <span class="o">+</span> <span class="n">basis_trunc</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">=</span> <span class="n">pred</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">mean_cov</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_cov</span><span class="p">:</span>
            <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">pred</span>
            <span class="k">return</span> <span class="n">mean</span><span class="p">,</span> <span class="n">cov</span> <span class="o">+</span> <span class="n">mean_cov</span></div></div>


<div class="viewcode-block" id="TruncationPointwise"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise">[docs]</a><span class="k">class</span> <span class="nc">TruncationPointwise</span><span class="p">:</span>
    <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A conjugacy-based implementation of the pointwise convergence model from Furnstahl et al. (2015)</span>

<span class="sd">    Implements the following model</span>

<span class="sd">    .. math::</span>

<span class="sd">        y_k = y_{\mathrm{ref}} \sum_{n=0}^k c_n Q^n</span>

<span class="sd">    where the :math:`c_n` are iid Gaussian random variables and :math:`\bar c^2` has a scaled inverse chi squared</span>
<span class="sd">    conjugate prior</span>

<span class="sd">    .. math::</span>

<span class="sd">        c_n \,|\, \bar c^2 &amp; \sim N(0, \bar c^2) \\</span>
<span class="sd">        \bar c^2 &amp; \sim \chi^{-2}(\nu_0, \tau_0^2)</span>

<span class="sd">    Conditioning on the partial sums :math:`y_0`, :math:`\dots,` :math:`y_k`, allow</span>
<span class="sd">    one to estimate :math:`\bar c`, and thus the full summation :math:`y_\infty`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : float &gt;= 0</span>
<span class="sd">        The degrees of freedom hyperparameter :math:`\nu_0` for the scaled inverse chi squared prior on :math:`\bar c`</span>
<span class="sd">    scale : float &gt; 0</span>
<span class="sd">        The scale hyperparameter :math:`\tau_0` for the scaled inverse chi squared prior on :math:`\bar c`</span>
<span class="sd">    excluded : int or array, optional</span>
<span class="sd">        The orders to be excluded from both the hyperparameter updating and from the truncation error distribution.</span>
<span class="sd">        Defaults to `None`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df0</span> <span class="o">=</span> <span class="n">df</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span> <span class="o">=</span> <span class="n">scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span> <span class="o">=</span> <span class="n">excluded</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orders_mask_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_orders_masked</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_dist_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_masked_</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_compute_df</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">df0</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">df0</span> <span class="o">+</span> <span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_compute_scale</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="p">):</span>
        <span class="n">c_sq</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_compute_df</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">df0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">df0</span> <span class="o">*</span> <span class="n">scale0</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">c_sq</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_num_orders</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_compute_order_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">orders</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">orders</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">orders</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">orders</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_orders_masked</span> <span class="o">==</span> <span class="n">order</span><span class="p">)</span> <span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="n">orders</span><span class="p">])</span>

<div class="viewcode-block" id="TruncationPointwise.fit"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y</span>
<span class="sd">        ratio</span>
<span class="sd">        ref</span>
<span class="sd">        orders</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y_</span> <span class="o">=</span> <span class="n">y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ratio_</span> <span class="o">=</span> <span class="n">ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_</span> <span class="o">=</span> <span class="n">ref</span>

        <span class="k">if</span> <span class="n">orders</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">orders</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">orders</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The last dimension of `y` must have the same size as `orders`&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span> <span class="o">=</span> <span class="n">orders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">orders_mask_</span> <span class="o">=</span> <span class="n">orders_mask</span> <span class="o">=</span> <span class="o">~</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">orders</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="n">orders</span><span class="p">)[:,</span> <span class="n">orders_mask</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_df</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_scale</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">coeffs_</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale0</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">y_masked_</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="n">orders_mask</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_orders_masked</span> <span class="o">=</span> <span class="n">orders_masked</span> <span class="o">=</span> <span class="n">orders</span><span class="p">[</span><span class="n">orders_mask</span><span class="p">]</span>
        <span class="n">ratio_sums</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">geometric_sum</span><span class="p">(</span><span class="n">ratio</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">excluded</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">excluded</span><span class="p">)</span>
                               <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">orders_masked</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
        <span class="n">trunc_scale</span> <span class="o">=</span> <span class="n">ref</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">ratio_sums</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coeffs_dist_</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">scale_</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">y_masked_</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">trunc_scale</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">df_</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="TruncationPointwise.interval"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.interval">[docs]</a>    <span class="k">def</span> <span class="nf">interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A convenience method to call `interval` on the truncation error distribution object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        alpha</span>
<span class="sd">        orders</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">alpha</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dist_</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_order_indices</span><span class="p">(</span><span class="n">orders</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">interval</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="TruncationPointwise.pdf"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.pdf">[docs]</a>    <span class="k">def</span> <span class="nf">pdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A convenience method to call `pdf` on the truncation error distribution object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y</span>
<span class="sd">        orders</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_order_indices</span><span class="p">(</span><span class="n">orders</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="TruncationPointwise.logpdf"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.logpdf">[docs]</a>    <span class="k">def</span> <span class="nf">logpdf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A convenience method to call `logpdf` on the truncation error distribution object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        y</span>
<span class="sd">        orders</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_order_indices</span><span class="p">(</span><span class="n">orders</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">idx</span><span class="p">]</span></div>

<div class="viewcode-block" id="TruncationPointwise.std"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.std">[docs]</a>    <span class="k">def</span> <span class="nf">std</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;A convenience method to call `std` on the truncation error distribution object.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span><span class="o">.</span><span class="n">std</span><span class="p">()</span></div>

<div class="viewcode-block" id="TruncationPointwise.log_likelihood"><a class="viewcode-back" href="../../api/models.html#gsum.models.TruncationPointwise.log_likelihood">[docs]</a>    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sa">R</span><span class="sd">&quot;&quot;&quot;Computes the log likelihood for the ratio and ref parameters given the data passed to `fit`.</span>

<span class="sd">        That is</span>

<span class="sd">        .. math::</span>
<span class="sd">            pr(\vec{y}_k \, | \, Q, y_{ref}) &amp; = \frac{pr(\vec{c}_k)}{\prod_n y_{ref} Q^n} \\</span>
<span class="sd">            pr(\vec{c}_k) &amp; = \frac{\Gamma(\nu/2)}{\Gamma(\nu_0/2)}</span>
<span class="sd">                              \sqrt{\frac{1}{(2\pi)^n} \frac{(\nu_0 \tau_0^2 / 2)^{\nu_0}}{(\nu \tau^2 / 2)^{\nu}}}</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        ratio : scalar or array, shape = (n_points,)</span>
<span class="sd">            The ratio, or EFT expansion parameter, in the geometric sum, used to extract the coefficients.</span>
<span class="sd">        ref : scalar or array, shape = (n_points,)</span>
<span class="sd">            The multiplicative reference scale used to extract the coefficients.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The log likelihood</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Must call fit before calling log_likelihood&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ratio</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ratio_</span>
        <span class="k">if</span> <span class="n">ref</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ref</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ref_</span>

        <span class="n">y</span><span class="p">,</span> <span class="n">orders</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">orders_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">orders_mask_</span>
        <span class="n">coeffs</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span> <span class="n">ref</span><span class="o">=</span><span class="n">ref</span><span class="p">,</span> <span class="n">orders</span><span class="o">=</span><span class="n">orders</span><span class="p">)[:,</span> <span class="n">mask</span><span class="p">]</span>
        <span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">df0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale0</span>
        <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_df</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_scale</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">df0</span><span class="o">=</span><span class="n">df0</span><span class="p">,</span> <span class="n">scale0</span><span class="o">=</span><span class="n">scale0</span><span class="p">)</span>

        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_orders</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span>
        <span class="n">log_like</span> <span class="o">=</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">df</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">df0</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Ignore this infinite constant for scale invariant prior, df0 == 0</span>
            <span class="n">log_like</span> <span class="o">+=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">df0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df0</span> <span class="o">*</span> <span class="n">scale0</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">))</span> <span class="o">-</span> <span class="n">loggamma</span><span class="p">(</span><span class="n">df0</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">)</span>
        <span class="n">log_like</span> <span class="o">-=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">df</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span> <span class="o">*</span> <span class="n">scale</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mf">2.</span><span class="p">))</span>
        <span class="n">log_like</span> <span class="o">-=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">ref</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">orders</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ratio</span><span class="p">))</span>  <span class="c1"># From change of variables</span>
        <span class="k">return</span> <span class="n">log_like</span></div>

    <span class="k">def</span> <span class="nf">credible_diagnostic</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">dobs</span><span class="p">,</span> <span class="n">band_intervals</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">band_dobs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span>
        <span class="n">dobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">dobs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="n">dobs</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">])</span>

        <span class="k">def</span> <span class="nf">diagnostic</span><span class="p">(</span><span class="n">data_</span><span class="p">,</span> <span class="n">lower_</span><span class="p">,</span> <span class="n">upper_</span><span class="p">):</span>
            <span class="n">indicator</span> <span class="o">=</span> <span class="p">(</span><span class="n">lower_</span> <span class="o">&lt;</span> <span class="n">data_</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">data_</span> <span class="o">&lt;</span> <span class="n">upper_</span><span class="p">)</span>  <span class="c1"># 1 if in, 0 if out</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">indicator</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># The diagnostic</span>

        <span class="c1"># D_CI = np.apply_along_axis(</span>
        <span class="c1">#         diagnostic, axis=0, arr=data, lower_=lower,</span>
        <span class="c1">#         upper_=upper)</span>
        <span class="n">D_CI</span> <span class="o">=</span> <span class="n">diagnostic</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">band_intervals</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">band_dobs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">band_dobs</span> <span class="o">=</span> <span class="n">dobs</span>
            <span class="n">band_dobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">band_dobs</span><span class="p">)</span>

            <span class="n">N</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">beta</span><span class="p">:</span>
                <span class="n">band_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">band_intervals</span><span class="p">)</span>
                <span class="c1"># Band shape: (len(dobs), 2, len(X))</span>
                <span class="n">bands</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">band_intervals</span><span class="p">),</span> <span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">band_dobs</span><span class="p">)))</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">band_intervals</span><span class="p">):</span>
                    <span class="n">bands</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
                        <span class="p">[</span><span class="n">hpd</span><span class="p">(</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">N</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">N</span><span class="o">*</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">band_dobs</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
                <span class="c1"># bands = np.transpose(bands, [0, 1, 2])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">band_dist</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">binom</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">band_dobs</span><span class="p">)</span>
                <span class="n">band_intervals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">band_intervals</span><span class="p">)</span>
                <span class="n">bands</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">band_dist</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="n">band_intervals</span><span class="o">.</span><span class="n">T</span><span class="p">))</span> <span class="o">/</span> <span class="n">N</span>
                <span class="n">bands</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">bands</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">D_CI</span><span class="p">,</span> <span class="n">bands</span>
        <span class="k">return</span> <span class="n">D_CI</span></div>
</pre></div>

          </div>
            
        </div>
        <div class="clearfix"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">gsum 0.1 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
<script type="text/javascript">
  $("#mobile-toggle a").click(function () {
    $("#left-column").toggle();
  });
</script>
<script type="text/javascript" src="../../_static/js/bootstrap.js"></script>
  <div class="footer">
    &copy; Copyright 2018, Jordan Melendez. Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  </body>
</html>